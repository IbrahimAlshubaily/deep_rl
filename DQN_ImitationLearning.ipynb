{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjPklEQVR4nO3de3wcZb3H8c+vaSopCq0SkFKg9AWEcsqlkBalyEWRIALlYhW8FDlwEEURkYhFPKJHDmpQ0IoKeMALKHLpRVAIFhGPehBSU2ilBEUrNoU2gCkUtjSX3/nj2bRJusludmd3Zyff9+u1rybPzM7zm9sv02eeecbcHRERSaYx5Q5ARESKR0leRCTBlORFRBJMSV5EJMGU5EVEEmxsuQPob6eddvIpU6aUOwwRkYqybNmy5929NtO0WCX5KVOm0NLSUu4wREQqipn9Y6hpaq4REUkwJXkRkQRTkhcRSTAleRGRBFOSFxFJsIJ615jZXOAKYBowy91b0uVTgFVAW3rWh939/ELqioPFre00NbextjPFpAk1NDbUccqM3codliSMjjOJUqFdKFcCpwHXZ5j2tLsfXODyY2NxazvzF64g1dUDQHtnivkLVwDoBJTI6DiTqBXUXOPuq9y9Lfucla+puW3Lidcn1dVDU/OoWH0pER1nErVitsnvZWatZvaQmb1tqJnM7DwzazGzlo6OjiKGU5i1nakRlYvkQ8eZRC1rkjezpWa2MsNnzjBfexbYw91nABcDPzGzHTLN6O43uHu9u9fX1mZ8KjcWJk2oGVG5SD50nEnUsiZ5dz/W3adn+CwZ5juvufsL6Z+XAU8D+0YXduk1NtRRU101oKymuorGhroyRSRJpONMolaUsWvMrBZ40d17zGwqsA/wt2LUVSp9N73U60GKSceZRM0KecermZ0KLABqgU5gubs3mNnpwJeAbqAH+IK7351tefX19a4BykRERsbMlrl7faZpBV3Ju/siYFGG8ruAuwpZtoiIFE5PvIqIJJiSvIhIginJi4gkmJK8iEiCKcmLiCSYkryISIIpyYuIJJiSvIhIginJi4gkmJK8iEiCKcmLiCSYkryISIIpyYuIJJiSvIhIginJi4gkmJK8iEiCKcmLiCSYkryISIIpyYuIJJiSvIhIginJi4gkmJK8iEiCKcmLiCSYkryISIKNLeTLZjYXuAKYBsxy95Z+0w4Ergd2AHqBme6+qZD6imlxaztNzW2s7UwxaUINjQ11nDJjt3KHJZK3qI7pcp4blXZexjHegpI8sBI4jZDMtzCzscAtwIfc/TEzexPQVWBdRbO4tZ35C1eQ6uoBoL0zxfyFKwDKvoNE8hHVMV3Oc6PSzsu4xltQc427r3L3tgyTjgMed/fH0vO94O49hdRVTE3NbVt2TJ9UVw9NzZlWTST+ojqmy3luVNp5Gdd4i9Umvy/gZtZsZn8ys88MNaOZnWdmLWbW0tHRUaRwhre2MzWicpG4i+qYLue5UWnnZVzjzZrkzWypma3M8JkzzNfGAkcAH0j/e6qZvSPTjO5+g7vXu3t9bW1tXitRqEkTakZULhJ3UR3T5Tw3Ku28jGu8WZO8ux/r7tMzfJYM87U1wEPu/ry7vwr8EjgkqqCj1thQR0111YCymuoqGhvqyhSRSGGiOqbLeW5U2nkZ13gLvfE6lGbgM2Y2HtgMHAVcU6S6CtZ3UyRud8VF8hXVMV3Oc6PSzsu4xmvunv+XzU4FFgC1QCew3N0b0tM+CMwHHPiluw/ZLt+nvr7eW1pass0mIiL9mNkyd6/PNK2gK3l3XwQsGmLaLYRulCIiUiZ64lVEJMGU5EVEEkxJXkQkwZTkRUQSTEleRCTBlORFRBJMSV5EJMGU5EVEEkxJXkQkwZTkRUQSTEleRCTBlORFRBJMSV5EJMGU5EVEEkxJXkQkwZTkRUQSTEleRCTBlORFRBJMSV5EJMGU5EVEEkxJXkQkwZTkRUQSTEleRCTBlORFRBJsbCFfNrO5wBXANGCWu7ekyz8ANPab9UDgEHdfXkh9pba4tZ2m5jbWdqaYNKGGxoY6TpmxW7nDEslLpuMZGPExnst5kc88x+xXy4NPdpTlfCvVuV6OnGLunv+XzaYBvcD1wCV9SX7QPAcAS9x9arbl1dfXe0vLNosoi8Wt7cxfuIJUV8+WsprqKq467QAleqk4mY7n6jEGBl09W3NAtmM8l/Mi33kGK9X5VqpzvZj1mNkyd6/PNK2g5hp3X+XubVlmOxP4aSH1lENTc9s2B2Cqq4em5myrKxI/mY7nrl4fkOAh+zGey3mR7zyDlep8K9W5Xq6cUoo2+fcxTJI3s/PMrMXMWjo6OkoQTm7WdqZGVC4SZyM5boebN5fzopB5RhJLVEp1rpcrp2RN8ma21MxWZvjMyeG7hwGvuvvKoeZx9xvcvd7d62tra0cYfvFMmlAzonKROBvJcTvcvLmcF4XMM5JYolKqc71cOSVrknf3Y919eobPkhyWfwYV2FQD0NhQR0111YCymuqqLTerRCpJpuO5eoxRXWUDyrId47mcF/nOM1ipzrdSnevlyikF9a4ZjpmNAeYCRxarjmLquxGi3jWSBEMdz5nKhjvGczkv8p2nXL1rSnWulyunFNq75lRgAVALdALL3b0hPe1o4Cvu/pZclxen3jUiIpViuN41BV3Ju/siYNEQ034D5JzgRUQkenriVUQkwZTkRUQSTEleRCTBlORFRBJMSV5EJMGU5EVEEkxJXkQkwZTkRUQSTEleRCTBlORFRBJMSV5EJMGU5EVEEkxJXkQkwZTkRUQSTEleRCTBlORFRBJMSV5EJMGU5EVEEkxJXkQkwZTkRUQSTEleRCTBlORFRBJMSV5EJMGU5EVEEmxsIV82s7nAFcA0YJa7t6TLq4HvA4ek6/iRu19VWKiVaXFrO03NbaztTDFpQg2NDXWcMmO3coc1pEzxAmVbh2zbL5d4j9mvlgef7Ch4naLal4OXkym+UsVS6fLdDqNp+5m75/9ls2lAL3A9cEm/JP9+4GR3P8PMxgNPAEe7++rhlldfX+8tLS15xxM3i1vbmb9wBamuni1lNdVVXHXaAbE8oDLFWz3GwKCrZ+txUqp1yLb9co13sHzWKap9mWk5g5UqlkqX73ZI4vYzs2XuXp9pWkHNNe6+yt3bMk0CtjezsUANsBl4qZC6KlFTc9s2J3Oqq4em5kybrPwyxdvV69skzFKtQ7btl2u8g+WzTlHty0zLGaxUsVS6fLfDaNt+xWqTvxN4BXgWeAa42t1fzDSjmZ1nZi1m1tLR0VGkcMpjbWdqROXlNpK4SrEO2bZf1DEMt7yo9mWu85cilkqX73YYbdsva5I3s6VmtjLDZ84wX5sF9ACTgL2AT5vZ1EwzuvsN7l7v7vW1tbV5rURcTZpQM6LychtJXKVYh2zbL+oYhlteVPsy1/lLEUuly3c7jLbtlzXJu/ux7j49w2fJMF97P3Cfu3e5+3rg90DG9qIka2yoo6a6akBZTXXVlht/cZMp3uoxRnWVDSgr1Tpk2365xjtYPusU1b7MtJzBShVLpct3O4y27VdQ75phPAO83cxuAcYDbwGuLVJdsdV3E6dS7uIPFW+mslKsQ7btl2u8UfSuiWpfZlrOSHvXVNpxVSz5bofRtv0K7V1zKrAAqAU6geXu3mBmrwduBvYHDLjZ3ZuyLS9pvWtEREphuN41BV3Ju/siYFGG8o3A3EKWLSIihdMTryIiCaYkLyKSYEryIiIJpiQvIvF1++3wpjfBIYdAYyN0dW2dtmEDPP443H033HnnwGmyhZK8iMTTt74FZ5wBU6fCjjvCL38J1dVh2hFHwIQJcNBBcPLJMHcuvPe9ZQ13i5YW2Lix3FFsUax+8iIi+XvhBfjyl+GUU+DWW6GmBnr6jTfzoQ/BnDkwZQrsuSf885/hih8glQpX9TvsMLI6UynYtAkmTswvZnf44hfDZ/fdw/8uZs0aOM9LL8Fdd8HZZ+dXRx6U5EUkPrq7oaoqJOz/+7+QxKvST6dW9XtK9SMfGfi9/sn0v/4LfvQj+OY34bTTwIZ/AnqLRx+Fo46C/faD2bPD/xZmz4a9986+jN5euPBCuO668D+K554Lf3wgJP/Nm+G734Urr4Tnn4dDD4UDDgjfOfNMOPzw3GLMh7vH5nPooYe6iIxSv/mN+6GHul92WWHL+eMf3Q86yB3cjzvOva0t83w9Pe4/+Yn7f/93+L231/3qq93f/W73CRPC98F9yZIwffVq96VL3Tds2HZZ110X5m1sDMvpX8dxx7nvvnuYfuyx7o8+Gqa1t7tPnhzKzznHvbMz71UGWnyIvFr2xN7/oyQvMgo9+aT7nDkhHU2e7P6znxW+zK4u9299y32HHdyrq91vuimUt7W5X3+9+wUXuE+fHuqsrw/z99fT475yZZi3oyOUXX11mN/Mfdo093nz3L/9bfeXX3Z/7TX3227bNo4NG9znznU/+mj3X/1q2+kvv+x+ySXuU6e6b9yY9+oOl+QLGtYgahrWQKRCPPEEdHbCW9+auSmjtxdefBF22mn45XznO/DJT4Y29/nz4aKLws9RWbcOPvtZ+PSnYfp0+MpXQj1veAMceGBo9vnAB2BMDn1QNmyAhx+GRx4JTTuPPBLuHbz0UuExb9oE222X99eHG9ZASV5EcvfCC3D55XDDDSGRv/OdsGTJwCT38MOhrXn8eHjwwVD21FNQlx7lsacHXnkl3Bh97DG4/nq44grYeefix79uXbjBuueeubfVD8U9LO/Nb44mtgIU7c1QIjKKPPEE7LMP3HgjfOIT8I1vwOTJWxP83/8OH/5wuLpfswbOPTeU33Yb7L8/nHde6NN+6KFwwQVh2kEHhav5UiR4gF12CTdzC03wEJYRgwSfjXrXiEhu6upCv/WPfSw0ffTXd6VeXR2aRy67LDSJADQ0hCv7b387/IHYY4/Q/VFKQs01IjK0detCn+7vfCdcAQ9l9Wr46U/hPe8JV/uZPPVUaMs+9dTQlCORKdpQwyKSYOvXw9vfHhL4mjXDJ/kpU8INzeHsu2/4SEkpyYvItjo6QoL/+9/DcAJHHFHuiCRPuvEqMpr95S/w7ndDfX0YAAzC05knnQRPPw333ANHH13WEKUwSvIio1FPD1xzTegr/oc/hGEENm8O08aNC1fyd98drualoqm5RmQ0+uEP4eKL4cQTQz/1SZMGTl++fGvvGKloSvIio4U7/OMf4SbpvHnwxjeGroyZ+owrwSeGmmtERoO1a+H448ODSv/6F4wdG4bxjeKhIIk1XcmLJN2dd4YxWlKp8JTqhAnljkhKSFfyIknlHgb8mjs3vF2ptRXOP19X76OMkrxIUnV3wzPPhHFm/vCHrQOEyahSUHONmc0FrgCmAbPcvSVdPg64HqgHeoFPuvtvCop0BBa3ttPU3MbazhSTJtTQ2FDHKTN2K0k9QMF1R7XcuMeXy3KLsd+iUqztEIne3jCOzB13hGF0c7x6j/s+iNO5fcx+tTz4ZEdst1WfgsauMbNphCR+PXBJvyR/AVDv7meb2c7AvcBMd+8dbnlRjF2zuLWd+QtXkOra+j7ImuoqrjrtgEh3QKZ6qscYGHT1bN2mI607quXGPb5clluM/RaVYm2HLZ5/Hm66KTyo9G//tu30zZvhF78I/duPPHLgtPvvD0MM3H33tl0jR7hOcdoHcTu3ByvntiraUMPuvsrd2zJM2h94ID3PeqCTcFVfdE3NbQN2DkCqq4em5kxhRltPV69vcxCMtO6olhv3+HJZbjH2W1SKtR22+MhH4NJLQ2+YVCqU9fbCn/8cXoAxefLA95euWAG33w5//COcfnpoqtl++4LXKU77IG7n9mBx2lb9Fat3zWPAHDO7DdgdODT97yODZzSz84DzAPbYY4+CK17bmRpRedT1xGXeuMeX67xR77eoFGs7ALBwYfhcdll4sXRNTbiJeuCBIcmPHQsnnwznnBP+CAD84Aeh5wzA7ruH8WZ23HFE1cZ9H8Tx3I7yu8WS9UrezJaa2coMn+EGhL4JWAO0ANcCfwC6M83o7je4e72719fW1uaxCgNNmpD5NVxDlUddT1zmjXt8uc4b9X6LSrG2A52d8PGPw8EHh7clHXdcKN+0KYzL/vWvhz7vd90FJ5wQEj7A174WmmkuuACam2G3kTcZxH0fxPHcjvK7xZI1ybv7se4+PcNnyTDf6Xb3T7n7we4+B5gA/CXCuIfU2FBHTXXVgLKa6qotN06KWU/1GKO6auANrpHWHdVy4x5fLsstxn6LSrG2A5s2wcyZ8P3vhxunWxZUExL8xRdDpouhqqrwKr5vfxumTRvJqmwR930Qt3N7sDhtq/6K0lxjZuMJN3VfMbN3At3u/kQx6hqs76ZHse/AD1VPoXVHtdy4x5frcuNwwy+TYm0H3vzm8M7UMoj7PojbuT1aetecCiwAagk3V5e7e4OZTQGaCT1v2oFz3P0f2ZanN0PJqLVpU3hF3vz5sNde5Y5GKkzR3gzl7ouARRnKVwPx+3+LSBy98EIYy/3mm8PTqUryEiGNXSNSLs88E3rE3HgjvPpqaG9/5zvLHZUkjIY1ECmXH/0IrrsuvPx65cpwY1UkYrqSFynEK6+EK/I1a7Z+nn0WvvjFbXvBrFwJX/5ySOrveU8YU2bePIjg+RCRoSjJy+i0YcPWh4VSKdhuu+zju3R2woIF4anSW24JQ/ZeeSVcddXA+aZMCfMBfOEL4WXYGzfCokXhZRxHHRWm7bjjiB9YEhkpNdfI6LJuHXzqU2FMl1WrQtkll4SnROfNCzc///a38IRpn5dfDsl8r73gP/8zXK13doZpc+fCrbfCQw+FF1+nUiGpV6X7WadScO+98Otfh++uXg0f/Wgp11hGOV3Jy+jw4ovhqdAFC+C110JC73vF3THHhB4u990HP/5xKDvsMHj44fB06UEHhQHDTjoJvvSl8DRqnxkzwmcoX/safOUr4Y9GVdXQ84kUiZK8JN+mTWEkx3Xr4MwzQxPKvvtund7XRt7bG67uH3oo/Azhiv/cc+HUU2HWrPzqH6P/MEv5FPQwVNT0MJREpqcnNJOceGL4/Yc/hEMOgQMOKG9cIkVQtKGGRWLp/vtDk8pJJ8HvfhfKzjpLCV5GJSV5SY62tnDl3tAQHi664w6YPbvcUYmUldrkJf46OuCNbxz+xmVXF7zjHfDSS+Fm54UXwuteV7oYRWJKV/ISX88+Cx/8IOy8c3gydLDeXrjzzvAWpOpq+MlP4K9/DePAKMGLAEryEoXubli2DJ56amtZT8/Q8+eyvGuvhbq60ORy5plw9tlh2v/+L/zpT9DaCkccEfqp33FHmHbkkeEPgohsoeYaGbneXnjggZBwf//78AToK6+EJpJvfjP0Kd9tN9h775Co99kndFk85hiYOjXzMvt6eZmFhH7LLaFtfcGC8P0+8+eHOseMCS+xvvlmeN/7ir/OIhVKSV5y8+CDoZ/5GWeERDxvHqxfHx4UOvvscIPzbW8L87qHp0qffDJ8fvEL2Lw5jLY4dSo8/nj4/t57h6dIV68OfzCWLoXp08Mfi9NOg1NO2XaogV/8Aq65JrTBNzaGoQVEZEhK8jK8554LA2ndeWe4Gu9L8vfdFxJ231Oj/dXWhqc8+/T0hEG8+sZp6e2FyZPDS6nvvht23TUMsdv30NDMmeGTyY47hnefikhOlOQlM/cwFO6nPhW6I155Zfi5z0EH5b6sqqqBL8I4+GC4556t9WQbGExE8qYkL5k99hh8+MOhGeb734f99itOPUrwIkWl3jWjSU9PuGl5zTVh4K3B3EMvGQhX2w8+CL/9bfESvIgUnZJ80m3cGNrTzzoL3vzm0O3w4ou3DsD1yivh3+eeg5NPDoNwLV8eyo4+WoNriVQ4NddUip6e0FVxw4bQo2TSJNhzz8zzdnSEvua77gqPPhr6kk+cCCecEMZzOeKI0MURYM6cMPTuqlXhD8LVV8OBB5ZstUSkuJTkK8Ell4QXUzz33Nay97xn60NAu+4akvqOO4Y3HK1aFW6SXn116Nb40ENw+OEwdtDudg9jvSxYEJpkbrwRpk0r3XqJSNEpycdNb+/Wh4wuuyyUrV8fboCefnropdLZGcZy6XPOOeGlFxs2hLcYnX56uHqHkNiPPDJzXWZw0UXhIyKJpPHkS+G3v4WbboJx48KV9nbbQU1NaCefOjW8bu6hh2DFCvjZz8JN0fHjw0NCg18GLSIyyHDjyRd0JW9mTcBJwGbgaeBsd+9MT5sPnAP0ABe6e3MhdRVicWs7Tc1trO1MMWlCDY0NdQDblJ0yY7fiBDBxYniBRVUVpFL0pFJUvfYaZ/ylhn8eOItPrn+E914zn9eqxvJw3WGM/8TlzPzEPNh++/iuUxaD4ztmv1oefLKjYuKNKr5My81nHXNZTlR15SNb3aWMLZdjLy7bJdd5ClHQlbyZHQf82t27zeyrAO5+qZntD/wUmAVMApYC+7r7sKNWFeNKfnFrO/MXriDVtbXq6jEGBl09W9e9prqKq047ILqN294Ot90Gn/50+D390M+WeDZ3YzhuY9iuaxNvevUlNmz3eja+bnzWWMq2TjnKFN9gcY83ivgyLTefdcxlOVHVlY9sdZcytlyOvbhsl1znyUXR3gzl7ve7e3f614eByemf5wC3uftr7v534K+EhF9yTc1t2+zwrl4fcPICpLp6aGpuK7xC9/Co/owZ4V2iq1eH8vRDP1viMcMtbP5N1dvRvuPObHzd+JxiKfk6jVCm+AaLe7xRxJdpufmsYy7LiaqufGSru5Sx5XLsxWW75DpPoaLsBP3vwL3pn3cD/tlv2pp02TbM7DwzazGzlo6OjgjDCdZ2pooy7zZefTX0Ztlvv9DffJddoKUFpkzJq47h5ivZOuWpkDrjHm8U8450HXNZTlR15SNb3aWMLYrzKypx2W9Zk7yZLTWzlRk+c/rN8zmgG7i1ryjDojK2C7n7De5e7+71tUW4yThpQk1R5gXCVXvfk6Njx0JTU7hR+sMfhv7pGZ4UzbWO4eYr6jpFoJA64x5vFPOOdB1zWU5UdeUjW92ljC2K8ysqcdlvWZO8ux/r7tMzfJYAmNlZwInAB3xrA/8aYPd+i5kMZHiOvvgaG+qoqR742rjqMUZ11cC/QzXVVVtutmW1cSN873vhoaHDDw8PKo0bB088EV4cPW9e6EGTYzyDZYulKOsUoVzWMe7xRhFfpuXms465LCequvKRre5SxhbF+VXMWMqx3wrtXXM8cClwlLu/2m/Sz4GfmNk3CDde9wEeKaSufPXdvIis58T3vgeXXhreJTpjBnz+86Fve1VVeIlFHvGM9O5/5OsUsVzXMc7xRhHfUMsd6Trmspyo6spHtrpLGVsU51cxYynHfiu0d81fgdcBL6SLHnb389PTPkdop+8GLnL3ezMvZavY95N/7rnwMNLMmfDVr8Jb3qJRFEWk7IrWT97d9x5m2pXAlYUsP3Z23hl+/GM45JChX2MnIhIjGtZgJMaMCWPGiIhUCI0jm6svfSm8HUlEpIIoyedi3brwztK20j+oIyJSCCX5XFx9dRhz/fLLyx2JiMiIKMlns349fOc78P73w777ljsaEZERUZLP5utfh02bdBUvIhVJvWuyOe200HWyrvRPYoqIFEpJfii9veFBp8MOCx8RkQqk5pqhXH55GIOmuzv7vCIiMaUkn8l998FVV4VX8A1++bWISAVRkh9szRr40IfCCJPXXlvuaERECqIk3193N5x5JqRScPvt4WXbIiIVTEm+v9bWMCb89derN42IJIIanPubOROeeQa2377ckYiIREJX8n1+97vwhicleBFJECV5gOXL4cgj4RvfKHckIiKRUpJ3h0sugYkT4dxzyx2NiEik1CZ/773wwAOhu+TEieWORkQkUqP7Sr67GxobYe+94aMfLXc0IiKRG91Jfs2akOi/+lUYN67c0YiIRG70Ndds3BiaaCZNgtmzYeVKDV0gIok1Oq7kN2yAH/8YTj4ZdtoJ3vteuPHGMK26Oow2KSKSQMm9hO3u3nqFfuSR8PjjsPvucP75YYz42bPLG5+ISAkkM8k/9BB87GNhmIJx48JLuCdOhFmzYMzo+M+LiAgUmOTNrAk4CdgMPA2c7e6dZvYm4E5gJvADd/94wZEOY3FrO03NbTz34kY+27qIc3/9I2zvveFf/4JddoF3vauY1Ve0vm23tjPFpAk1NDbUccqM3cod1pAqLV6Rciv0svZXwHR3PxB4CpifLt8EfB64pMDlZ7W4tZ35C1fwWvtafnD7F/iPpT/g7v2P4p7/+XlI8DKkvm3X3pnCgfbOFPMXrmBxa3u5Q8uo0uIViYOCkry73+/ufa9OehiYnC5/xd1/R0j2RdXU3Eaqq4cv/up7zGx/gs8cfyEXnnAxV/1OJ342fduuv1RXD03NbWWKaHiVFq9IHETZJv/vwM9G+iUzOw84D2CPPfYYcaVrO1MAfOkd/8G3Zp9JW+2UAeUytKG2UVy3XaXFKxIHWa/kzWypma3M8JnTb57PAd3ArSMNwN1vcPd6d6+vra0d6deZNCG82GPdG3bakuD7l8vQhtpGcd12lRavSBxkTfLufqy7T8/wWQJgZmcBJwIfcHcvdsCDNTbUUVNdNaCsprqKxga99CObStt2lRavSBwU2rvmeOBS4Ch3fzWakEamr2eFelyMXKVtu0qLVyQOrJCLbzP7K/A64IV00cPufn562mpgB2Ac0Akc5+5PDLe8+vp6b2lpyTseEZHRyMyWuXt9pmkFXcm7+97DTJtSyLJFRKRwevxTRCTBlORFRBJMSV5EJMGU5EVEEqyg3jVRM7MO4B8FLGIn4PmIwikFxVtcire4FG9xjSTePd0949OksUryhTKzlqG6EcWR4i0uxVtcire4oopXzTUiIgmmJC8ikmBJS/I3lDuAEVK8xaV4i0vxFlck8SaqTV5ERAZK2pW8iIj0oyQvIpJgiUjyZna8mbWZ2V/N7LPljmcwM7vJzNab2cp+ZW80s1+Z2V/S/04sZ4z9mdnuZvagma0ysz+b2SfT5bGM2cy2M7NHzOyxdLxfTJfHMt4+ZlZlZq1mdk/697jHu9rMVpjZcjNrSZfFNmYzm2Bmd5rZk+lj+a1xjdfM6tLbte/zkpldFEW8FZ/kzawKuA54F7A/cKaZ7V/eqLbxA+D4QWWfBR5w932AB9K/x0U38Gl3nwa8BbggvU3jGvNrwNvd/SDgYOB4M3sL8Y23zyeBVf1+j3u8AMe4+8H9+m/HOeZvAve5+37AQYRtHct43b0tvV0PBg4FXgUWEUW87l7RH+CtQHO/3+cD88sdV4Y4pwAr+/3eBuya/nlXoK3cMQ4T+xLgnZUQMzAe+BNwWJzjJbz0/gHg7cA9lXBMAKuBnQaVxTJmwrss/k66c0nc4x0U43HA76OKt+Kv5IHdgH/2+31NuizudnH3ZwHS/+5c5ngyMrMpwAzgj8Q45nTTx3JgPfArd491vMC1wGeA3n5lcY4XwIH7zWyZmZ2XLotrzFOBDuDmdJPY981se+Ibb39nAD9N/1xwvElI8pahTP1CI2BmrwfuAi5y95fKHc9w3L3Hw391JwOzzGx6mUMakpmdCKx392XljmWEZrv7IYSm0QvM7MhyBzSMscAhwHfdfQbwCjFpmhmOmY0DTgbuiGqZSUjya4Dd+/0+GVhbplhGYp2Z7QqQ/nd9meMZwMyqCQn+VndfmC6OdcwA7t4J/IZwDySu8c4GTk6/IvM24O1mdgvxjRcAd1+b/nc9ob14FvGNeQ2wJv0/OoA7CUk/rvH2eRfwJ3dfl/694HiTkOQfBfYxs73SfwXPAH5e5phy8XPgrPTPZxHavWPBzAz4H2CVu3+j36RYxmxmtWY2If1zDXAs8CQxjdfd57v7ZA+vyDwD+LW7f5CYxgtgZtub2Rv6fia0G68kpjG7+3PAP82sLl30DuAJYhpvP2eytakGooi33DcZIrpRcQLwFPA08Llyx5Mhvp8CzwJdhCuMc4A3EW68/SX97xvLHWe/eI8gNHk9DixPf06Ia8zAgUBrOt6VwH+my2MZ76DYj2brjdfYxkto434s/flz33kW85gPBlrSx8ViYGLM4x0PvADs2K+s4Hg1rIGISIIloblGRESGoCQvIpJgSvIiIgmmJC8ikmBK8iIiCaYkLyKSYEryIiIJ9v/vxqOMbHg6XQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pygame  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "class pong():\n",
    "    def __init__(self) -> None:\n",
    "        pygame.init()  \n",
    "        self.step_size = 4\n",
    "        self.screen_width, self.screen_height = 400,400\n",
    "        self.screen = pygame.display.set_mode((self.screen_width, self.screen_height))  \n",
    "        self.ball = self.ball(screen_width = self.screen_width, screen_height = self.screen_height, step_size = self.step_size)\n",
    "        self.player_one = self.pad(x = 10, screen_width = self.screen_width, screen_height = self.screen_height, step_size = self.step_size)\n",
    "        self.player_two = self.pad(x = self.screen_width - 20, screen_width = self.screen_width, screen_height = self.screen_height, step_size = self.step_size)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.ball.reset()\n",
    "        self.player_one.reset()\n",
    "        self.player_two.reset()\n",
    "        self.player_one_score = 0\n",
    "        self.player_two_score = 0\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self):\n",
    "        dx,dy = self.ball.dx/self.step_size, self.ball.dy/self.step_size\n",
    "        state_a = abs(self.ball.x - self.player_one.x) / self.screen_width , (self.ball.y - (self.player_one.y + (self.player_one.height / 2))) / self.screen_height, -dx, dy\n",
    "        state_b = abs(self.ball.x - self.player_two.x) / self.screen_width , (self.ball.y - (self.player_two.y + (self.player_two.height / 2))) / self.screen_height, dx, dy\n",
    "        return np.array([state_a, state_b])\n",
    "\n",
    "    def step(self, action):\n",
    "        action[0] = 1 if self.ball.y < self.player_one.y + (self.player_one.height / 2) else 0\n",
    "        self.player_one.step(action[0])\n",
    "        self.player_two.step(action[1])\n",
    "        reward = self.ball.step()\n",
    "        self.player_one_score += 1 if reward[0] == 1 else 0\n",
    "        self.player_two_score += 1 if reward[1] == 1 else 0\n",
    "        for i, pad in enumerate([self.player_one, self.player_two]):\n",
    "            if (abs(pad.x - self.ball.x) <= self.step_size) and (abs(pad.y + (pad.height / 2) - self.ball.y) <= (pad.height / 2)):\n",
    "                self.ball.dx = -self.ball.dx    \n",
    "                self.ball.x += 2*self.ball.dx    \n",
    "                self.ball.dy += np.random.rand() if np.random.rand() < 0.5 else -np.random.rand()\n",
    "\n",
    "        return self.get_state(), action, reward, max(self.player_one_score, self.player_two_score) == 21\n",
    "\n",
    "    def render(self):\n",
    "        self.screen.fill((0,0,0))\n",
    "        self.ball.draw(self.screen)\n",
    "        self.player_one.draw(self.screen)\n",
    "        self.player_two.draw(self.screen)\n",
    "        pygame.display.update()\n",
    "\n",
    "    class pad():\n",
    "        def __init__(self, x, screen_width, screen_height, step_size) -> None:\n",
    "            self.x = x\n",
    "            self.width = 10\n",
    "            self.height = 40\n",
    "            self.step_size = step_size\n",
    "            self.screen_width = screen_width\n",
    "            self.screen_height = screen_height\n",
    "            self.reset()\n",
    "\n",
    "        def reset(self):\n",
    "            self.y = self.screen_height//2\n",
    "\n",
    "        def step(self, action):\n",
    "            step_is_valid = not ((self.y <= 0 and action)  or (self.y + self.height > self.screen_height and not action))\n",
    "            if step_is_valid:\n",
    "                self.y += -self.step_size if action else self.step_size \n",
    "\n",
    "        def draw(self, screen):\n",
    "            pygame.draw.rect(screen, (255, 255, 255), pygame.Rect(self.x, self.y, self.width, self.height))  \n",
    "\n",
    "    class ball():\n",
    "        def __init__(self, screen_width, screen_height, step_size) -> None:\n",
    "            self.radius = 5\n",
    "            self.step_size = step_size\n",
    "            self.screen_width = screen_width\n",
    "            self.screen_height = screen_height\n",
    "            self.reset()\n",
    "            \n",
    "        def reset(self):\n",
    "            self.x = self.screen_width//2\n",
    "            self.y = np.random.rand()*self.screen_height\n",
    "            self.dx = self.step_size if np.random.rand() < 0.5 else -self.step_size \n",
    "            self.dy = self.step_size if np.random.rand() < 0.5 else -self.step_size \n",
    "\n",
    "        def step(self):\n",
    "            self.x += self.dx\n",
    "            self.y += self.dy\n",
    "            reward = 0, 0\n",
    "            if self.x < 0 or self.x > self.screen_width:\n",
    "                reward = (-1,1) if self.x < 0 else (1,-1)\n",
    "                self.reset()\n",
    "            elif self.y <= 0 or self.y > self.screen_height-self.radius:\n",
    "                self.dy = -self.dy\n",
    "            return reward\n",
    "        \n",
    "        def draw(self, screen):\n",
    "            pygame.draw.circle(screen, (255, 255, 255),(self.x,self.y), self.radius)\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity, state_dim):\n",
    "        self.idx = 0\n",
    "        self.is_full = False\n",
    "        self.capacity = capacity\n",
    "        self.state_running_mean = None\n",
    "        self.state_running_std = None\n",
    "        self.memory = {'state':np.zeros((capacity, state_dim), dtype=np.float32),\n",
    "                        'action':np.zeros((capacity), dtype=int),\n",
    "                        'reward':np.zeros((capacity), dtype=np.float32),\n",
    "                        'next_state':np.zeros((capacity, state_dim), dtype=np.float32),\n",
    "                        'done':np.zeros((capacity), dtype=bool)}\n",
    "\n",
    "    def push_episode(self, batch):\n",
    "        for ind, k in enumerate(self.memory.keys()):\n",
    "            i,j = self.idx, min(self.idx+len(batch[0]), self.capacity)\n",
    "            self.memory[k][i:j] = batch[ind][:j-i]\n",
    "        self.idx += len(batch[0])\n",
    "        if self.idx >= self.capacity:\n",
    "            self.idx, self.is_full = 0, True\n",
    "\n",
    "    def sample_batch(self, batch_size = 256):\n",
    "        sample_idx = np.random.choice(self.__len__(), batch_size, replace=True) \n",
    "        return [self.memory[k][sample_idx] for k in self.memory.keys()]           \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.capacity if self.is_full else self.idx\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, state_dim, h_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential( nn.Linear(state_dim, h_dim), nn.ReLU(),\\\n",
    "                                     nn.Linear(h_dim, h_dim*2), nn.ReLU(),\\\n",
    "                                     nn.Linear(h_dim*2, action_dim))\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class dqn_agent():\n",
    "    def __init__(self, state_dim, h_dim, action_dim) -> None:\n",
    "        self.step = 0\n",
    "        self.gamma = 0.99\n",
    "        self.update_step_interval = 4\n",
    "        self.init_random_steps = 10000\n",
    "        self.update_target_network = 10000\n",
    "        self.epsilon, self.epsilon_min, epsilon_greedy_steps = 1.0, 0.0, 1e+6\n",
    "        self.epsilon_decay_step = (self.epsilon - self.epsilon_min) / epsilon_greedy_steps\n",
    "\n",
    "        self.num_actions = action_dim\n",
    "        self.model = MLP(state_dim, h_dim, action_dim)\n",
    "        self.target_model = MLP(state_dim, h_dim, action_dim)\n",
    "        self.loss_fn = torch.nn.HuberLoss()\n",
    "        self.optimizer = torch.optim.RMSprop(self.model.parameters(), lr=0.00025)\n",
    "        self.replay_buffer = ReplayBuffer(capacity=int(1e+7), state_dim=state_dim)\n",
    "        self.reset_memory()\n",
    "\n",
    "    def reset_memory(self):\n",
    "        self.states, self.actions, self.rewards, self.next_states, self.dones = [], [], [], [], []\n",
    "\n",
    "    def TD(self, arr, lambda_):\n",
    "        for i in range(len(arr)):\n",
    "            arr[i] = arr[min(i+lambda_, len(arr)-1)]\n",
    "        return arr\n",
    "\n",
    "    def push_step(self, s, a, r, ns, done):\n",
    "        self.states.extend(s), self.actions.extend(a), self.rewards.extend(r), self.next_states.extend(ns), self.dones.extend(done)\n",
    "        if done:\n",
    "\n",
    "            self.replay_buffer.push_episode([self.states[::2], self.actions[::2], \\\n",
    "                self.discounted_rewards(self.rewards[::2]), self.TD(self.next_states[::2], 5), self.dones[::2]])\n",
    "\n",
    "            self.replay_buffer.push_episode([self.states[1::2], self.actions[1::2], \\\n",
    "                self.discounted_rewards(self.rewards[1::2]), self.TD(self.next_states[1::2], 5), self.dones[1::2]])\n",
    "\n",
    "            self.reset_memory()\n",
    "\n",
    "    def select_action(self, state):\n",
    "        self.step+=1\n",
    "        self.epsilon = max(self.epsilon-self.epsilon_decay_step, self.epsilon_min)\n",
    "        if self.epsilon > np.random.rand():\n",
    "            return [np.random.choice(self.num_actions), np.random.choice(self.num_actions)]\n",
    "\n",
    "        return self.model(torch.FloatTensor(state)).argmax(dim=1).numpy()\n",
    "\n",
    "    def discounted_rewards(self, rewards, discount_rate = 0.98):\n",
    "        for i in reversed(range(len(rewards)-1)):\n",
    "            if rewards[i] == 0:  \n",
    "                rewards[i] += discount_rate * rewards[i+1]\n",
    "        return rewards\n",
    "    \n",
    "    def ddqn_loss(self, batch):\n",
    "        states, actions, rewards, next_states, dones = batch\n",
    "        with torch.no_grad():\n",
    "            future_action = self.model(next_states).argmax(dim=1).unsqueeze(1)\n",
    "            future_rewards = self.target_model(next_states).detach().gather(1, future_action).squeeze()\n",
    "        target_q_values = rewards + self.gamma * (future_rewards * (1 - dones))\n",
    "        q_values = self.model(states).gather(1, actions.unsqueeze(1)).squeeze()\n",
    "        return self.loss_fn(q_values, target_q_values)\n",
    "    \n",
    "    def training_step(self):\n",
    "        if self.step % self.update_step_interval == 0 and self.step > self.init_random_steps:\n",
    "            states, actions, rewards, next_state, done = self.replay_buffer.sample_batch()\n",
    "            states, actions, rewards, next_state, done = torch.FloatTensor(states), torch.LongTensor(actions), \\\n",
    "                                                            torch.FloatTensor(rewards), torch.FloatTensor(next_state), torch.IntTensor(done)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.ddqn_loss([states, actions, rewards, next_state, done])\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(self.model.parameters(), max_norm=2)\n",
    "            self.optimizer.step()\n",
    "\n",
    "        if self.step % self.update_target_network == 0:\n",
    "            self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "def plot_durations(durations, duration_running_avgs):\n",
    "    clear_output()\n",
    "    plt.plot(np.arange(len(durations)), duration_running_avgs, 'r--')\n",
    "    plt.scatter(np.arange(len(durations)), durations)\n",
    "    plt.show()\n",
    "\n",
    "env = pong()\n",
    "reward_sum = 0\n",
    "state = env.reset()\n",
    "next_state = np.zeros(state.shape)\n",
    "durations, duration_running_avgs = [-21], [-21]\n",
    "agent = dqn_agent(state_dim = len(state[0]), h_dim = 32, action_dim = 2)\n",
    "while True:\n",
    "    env.render()\n",
    "    action = agent.select_action(state)\n",
    "    next_state, action, reward, done = env.step(action)\n",
    "    reward_sum += reward[1]\n",
    "    agent.push_step(state, action, reward, next_state, [done,done])\n",
    "    agent.training_step()\n",
    "    state = next_state\n",
    "    if done:\n",
    "        durations.append(reward_sum)\n",
    "        duration_running_avgs.append( 0.95 * duration_running_avgs[-1] + 0.05 * durations[-1])\n",
    "        state = env.reset()\n",
    "        reward_sum=0\n",
    "        if len(durations) % 10 == 0:\n",
    "            plot_durations(durations, duration_running_avgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79e1e1b0b866e24ce4d1bc26029bd24cd96b791d20adadda89be48c72aa476c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
